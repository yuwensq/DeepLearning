{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GAN first introduction\n",
    "![GAN picture](./gan.png)\n",
    "\n",
    "\n",
    "\n",
    "GANs are a class of unsupervised generative models which implicitly model the data density.\n",
    "\n",
    "The basic setup is pictured above. There are two \"competing\" neural networks:\n",
    "* The Generator wants to learn to generate realistic images that are indistinguishable from the real data. \n",
    "    - *input*: Gaussian noise random sample. *output*: a (higher dimensional) datapoint\n",
    "* The Discriminator wants to tell the real & fake images apart.\n",
    "    - *input*: datapoint/image, *output*: probability assigned to datapoint being real. Think binary classifier.\n",
    "* The typical analogy: the generator is like a counterfeiter trying to look like real, the discriminator is the police trying to tell counterfeits from the real work.\n",
    "* The key novelty of GANs is to pass the error signal (gradients) from the discriminator to the generator: the generator neural network uses the information from the competing discriminator neural network to know how to produce more realistic output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the neural networks in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]\n",
      "1.13.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import sys\n",
    "print(sys.version) # python 3.6\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "print(torch.__version__) # 1.0.1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_imgs(x, new_fig=True):\n",
    "    grid = vutils.make_grid(x.detach().cpu(), nrow=8, normalize=True, pad_value=0.3)\n",
    "    grid = grid.transpose(0,2).transpose(0,1) # channels as last dimension\n",
    "    if new_fig:\n",
    "        plt.figure()\n",
    "    plt.imshow(grid.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a small 2-layer fully connected neural network (so one hidden layer) for the discriminator D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_channels=1, features=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # define the model\n",
    "        self.model = nn.Sequential(\n",
    "            # define the first Conv block\n",
    "            nn.Conv2d(image_channels, features, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # Conv block 2 \n",
    "            nn.Conv2d(features, features*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "    \n",
    "            # Conv block 3\n",
    "            nn.Conv2d(features*2, features*4, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(features*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # Conv block 4\n",
    "            nn.Conv2d(features*4, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a small 2-layer neural network for the generator G. G takes a 100-dimensional noise vector and generates an output of the size matching the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_channels=100, image_channels=1, features=24):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Transpose block 1\n",
    "            nn.ConvTranspose2d(noise_channels, features*8, kernel_size=4, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Transpose block 2\n",
    "            nn.ConvTranspose2d(features*8, features*4, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(features*4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Transpose block 3\n",
    "            nn.ConvTranspose2d(features*4, features*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features*2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Last transpose block (different)\n",
    "            nn.ConvTranspose2d(features*2, image_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): ConvTranspose2d(100, 192, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(192, 96, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU()\n",
      "    (5): ConvTranspose2d(96, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): ConvTranspose2d(48, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate a Generator and Discriminator according to their class definition.\n",
    "D = Discriminator()\n",
    "print(D)\n",
    "G = Generator()\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and computing forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # let's download the Fashion MNIST data, if you do this locally and you downloaded before,\n",
    "    # you can change data paths to point to your existing files\n",
    "    # dataset = torchvision.datasets.MNIST(root='./MNISTdata', ...)\n",
    "    dataset = torchvision.datasets.FashionMNIST(root='./FashionMNIST/',\n",
    "                           transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                         transforms.Normalize((0.5,), (0.5,))]),\n",
    "                           download=True)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together: the full training loop\n",
    "\n",
    "Modifications to the code:\n",
    "* add device parameter to take GPU if available\n",
    "* use [Adam optimizer](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) (an adaptive learning-rate variation of SGD with momentum)\n",
    "* some very minimal logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Epoch: 0 D Loss: tensor(0.0241, device='cuda:0') G Loss tensor(0.0359, device='cuda:0')\n",
      "Epoch: 1 D Loss: tensor(0.0172, device='cuda:0') G Loss tensor(0.0245, device='cuda:0')\n",
      "Epoch: 2 D Loss: tensor(0.0150, device='cuda:0') G Loss tensor(0.0299, device='cuda:0')\n",
      "Epoch: 3 D Loss: tensor(0.0139, device='cuda:0') G Loss tensor(0.0327, device='cuda:0')\n",
      "Epoch: 4 D Loss: tensor(0.0130, device='cuda:0') G Loss tensor(0.0363, device='cuda:0')\n",
      "Epoch: 5 D Loss: tensor(0.0124, device='cuda:0') G Loss tensor(0.0384, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Device: ', device)\n",
    "# Re-initialize D, G:\n",
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "# Now let's set up the optimizers (Adam, better than SGD for this)\n",
    "optimizerD = torch.optim.SGD(D.parameters(), lr=0.03)\n",
    "optimizerG = torch.optim.SGD(G.parameters(), lr=0.03)\n",
    "criterion = nn.BCELoss()\n",
    "# optimizerD = torch.optim.Adam(D.parameters(), lr=0.0005)\n",
    "# optimizerG = torch.optim.Adam(G.parameters(), lr=0.0005)\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "data_num = len(dataloader.dataset)\n",
    "\n",
    "# for logging:\n",
    "collect_x_gen = []\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "fig = plt.figure() # keep updating this one\n",
    "plt.ion()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs): # 3 epochs\n",
    "    d_loss = 0.\n",
    "    g_loss = 0.\n",
    "    for i, (x_real, _) in enumerate(dataloader):\n",
    "        x_real = x_real.to(device)\n",
    "        batch_size = x_real.shape[0]\n",
    "        # reset accumulated gradients from previous iteration\n",
    "        optimizerD.zero_grad()\n",
    "        label = (torch.ones(batch_size)).to(device)\n",
    "\n",
    "        D_x = D(x_real).reshape(-1)\n",
    "        lossD_real = criterion(D_x, label)\n",
    "\n",
    "        z = torch.randn(batch_size, 100, 1, 1, device=device) # random noise, 64 samples, z_dim=100\n",
    "        x_gen = G(z).detach()\n",
    "        label = (torch.ones(batch_size) * 0).to(device)\n",
    "        D_G_z = D(x_gen).reshape(-1)\n",
    "#         print(\"l\", label.shape)\n",
    "#         print(\"b\", D_G_z.shape)\n",
    "        lossD_fake = criterion(D_G_z, label)\n",
    "\n",
    "        lossD = lossD_real + lossD_fake\n",
    "        lossD.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # STEP 2: Generator optimization step\n",
    "        # reset accumulated gradients from previous iteration\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        z = torch.randn(batch_size, 100, 1, 1, device=device) # random noise, 64 samples, z_dim=100\n",
    "        x_gen = G(z)\n",
    "        label = (torch.ones(batch_size)).to(device)\n",
    "        D_G_z = D(x_gen).reshape(-1)\n",
    "        lossG = criterion(D_G_z, label) # -log D(G(z))\n",
    "\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            d_loss += lossD\n",
    "            g_loss += lossG\n",
    "            \n",
    "    # End of epoch\n",
    "    x_gen = G(fixed_noise)\n",
    "    collect_x_gen.append(x_gen.detach().clone())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        D_loss.append(d_loss / data_num)\n",
    "        G_loss.append(g_loss / data_num)\n",
    "        print('Epoch:', epoch, \"D Loss:\", d_loss / data_num, \"G Loss\", g_loss / data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = [i.data.cpu().numpy() for i in D_loss]\n",
    "G_loss = [i.data.cpu().numpy() for i in G_loss]\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     D_loss[i] = D_loss[i].data.cpu().numpy()\n",
    "#     G_loss[i] = G_loss[i].data.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), D_loss)\n",
    "plt.title('D loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), G_loss)\n",
    "plt.title('G loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_gen in collect_x_gen:\n",
    "    show_imgs(x_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_num = torch.randn(8, 100,1,1, device=device)\n",
    "gen_pics = G(rand_num)\n",
    "show_imgs(gen_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(8, 100, 1, 1, device=device)\n",
    "fixed_noise =fixed_noise.repeat(5, 1, 1, 1)\n",
    "\n",
    "rand_val = 0.1\n",
    "pos = 0\n",
    "for i in range(40):\n",
    "    fixed_noise[i][pos][0][0] = rand_val\n",
    "    if i % 8 == 7:\n",
    "        pos += 20\n",
    "x_gen = G(fixed_noise)\n",
    "show_imgs(x_gen)\n",
    "\n",
    "rand_val = 10\n",
    "pos = 0\n",
    "for i in range(40):\n",
    "    fixed_noise[i][pos][0][0] = rand_val\n",
    "    if i % 8 == 7:\n",
    "        pos += 20\n",
    "x_gen = G(fixed_noise)\n",
    "show_imgs(x_gen)\n",
    "\n",
    "rand_val = 100\n",
    "pos = 0\n",
    "for i in range(40):\n",
    "    fixed_noise[i][pos][0][0] = rand_val\n",
    "    if i % 8 == 7:\n",
    "        pos += 20\n",
    "x_gen = G(fixed_noise)\n",
    "show_imgs(x_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
